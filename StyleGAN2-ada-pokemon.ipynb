{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfTmFHC6WgQe",
        "outputId": "740608ff-6e8b-4b18-9bc7-8436fc77f380"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjEWhx16S5VB",
        "outputId": "8d5e7e79-87dd-4e77-8a27-bbef6835b66f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'stylegan2-ada-pytorch'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 128 (delta 19), reused 18 (delta 18), pack-reused 90\u001b[K\n",
            "Receiving objects: 100% (128/128), 1.12 MiB | 30.20 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2w53G5nT6pe",
        "outputId": "75eb4154-59dc-4503-bbec-0c55c697476b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  \u001b[01;34mstylegan2-ada-pytorch\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7NOb3SbUMn_",
        "outputId": "8b8d45b6-cff5-41d6-bc43-8c75c0c386b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/stylegan2-ada-pytorch\n"
          ]
        }
      ],
      "source": [
        "%cd stylegan2-ada-pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sj3SKbouUPwc",
        "outputId": "f3cbb466-bd63-4f3f-ffe7-c2d346ad1f72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-02-03 13:12:47--  https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220203%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220203T131247Z&X-Amz-Expires=300&X-Amz-Signature=218e8ec43ebd0f2fa560dd9b29a188456f96b7663fe6c3854037e05992dc8d57&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-02-03 13:12:47--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220203%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220203T131247Z&X-Amz-Expires=300&X-Amz-Signature=218e8ec43ebd0f2fa560dd9b29a188456f96b7663fe6c3854037e05992dc8d57&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77854 (76K) [application/octet-stream]\n",
            "Saving to: ‘ninja-linux.zip’\n",
            "\n",
            "ninja-linux.zip     100%[===================>]  76.03K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2022-02-03 13:12:48 (9.12 MB/s) - ‘ninja-linux.zip’ saved [77854/77854]\n",
            "\n",
            "Archive:  ninja-linux.zip\n",
            "  inflating: /usr/local/bin/ninja    \n",
            "update-alternatives: using /usr/local/bin/ninja to provide /usr/bin/ninja (ninja) in auto mode\n"
          ]
        }
      ],
      "source": [
        "# build ninja executable\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng22Y6FrUXWU",
        "outputId": "16b2a7ed-97a7-4f8f-a42b-69e6cd569226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1aAJCZbXNHyraJ6Mi13dSbe7pTyfPXha0\n",
            "To: /content/stylegan2-ada-pytorch/few-shot-image-datasets.zip\n",
            "100% 913M/913M [00:07<00:00, 118MB/s]\n"
          ]
        }
      ],
      "source": [
        "# get pokemon datasets\n",
        "!gdown https://drive.google.com/u/0/uc?id=1aAJCZbXNHyraJ6Mi13dSbe7pTyfPXha0&export=download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Qm1b9O5UXtv"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unzip few-shot-image-datasets.zip\n",
        "!mv few-shot-images data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orzV3EceUjy9",
        "outputId": "b4f214b5-1231-463c-cac1-6c6bf7fbbf01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usage: dataset_tool.py [OPTIONS]\n",
            "\n",
            "  Convert an image dataset into a dataset\n",
            "  archive usable with StyleGAN2 ADA PyTorch.\n",
            "\n",
            "  The input dataset format is guessed from the\n",
            "  --source argument:\n",
            "\n",
            "  --source *_lmdb/                    Load LSUN dataset\n",
            "  --source cifar-10-python.tar.gz     Load CIFAR-10 dataset\n",
            "  --source train-images-idx3-ubyte.gz Load MNIST dataset\n",
            "  --source path/                      Recursively load all images from path/\n",
            "  --source dataset.zip                Recursively load all images from dataset.zip\n",
            "\n",
            "  Specifying the output format and path:\n",
            "\n",
            "  --dest /path/to/dir                 Save output files under /path/to/dir\n",
            "  --dest /path/to/dataset.zip         Save output files into /path/to/dataset.zip\n",
            "\n",
            "  The output dataset format can be either an\n",
            "  image folder or an uncompressed zip archive.\n",
            "  Zip archives makes it easier to move datasets\n",
            "  around file servers and clusters, and may\n",
            "  offer better training performance on network\n",
            "  file systems.\n",
            "\n",
            "  Images within the dataset archive will be\n",
            "  stored as uncompressed PNG. Uncompresed PNGs\n",
            "  can be efficiently decoded in the training\n",
            "  loop.\n",
            "\n",
            "  Class labels are stored in a file called\n",
            "  'dataset.json' that is stored at the dataset\n",
            "  root folder.  This file has the following\n",
            "  structure:\n",
            "\n",
            "  {\n",
            "      \"labels\": [\n",
            "          [\"00000/img00000000.png\",6],\n",
            "          [\"00000/img00000001.png\",9],\n",
            "          ... repeated for every image in the datase\n",
            "          [\"00049/img00049999.png\",1]\n",
            "      ]\n",
            "  }\n",
            "\n",
            "  If the 'dataset.json' file cannot be found,\n",
            "  the dataset is interpreted as not containing\n",
            "  class labels.\n",
            "\n",
            "  Image scale/crop and resolution requirements:\n",
            "\n",
            "  Output images must be square-shaped and they\n",
            "  must all have the same power-of-two\n",
            "  dimensions.\n",
            "\n",
            "  To scale arbitrary input image size to a\n",
            "  specific width and height, use the --width and\n",
            "  --height options.  Output resolution will be\n",
            "  either the original input resolution (if\n",
            "  --width/--height was not specified) or the one\n",
            "  specified with --width/height.\n",
            "\n",
            "  Use the --transform=center-crop or\n",
            "  --transform=center-crop-wide options to apply\n",
            "  a center crop transform on the input image.\n",
            "  These options should be used with the --width\n",
            "  and --height options.  For example:\n",
            "\n",
            "  python dataset_tool.py --source LSUN/raw/cat_lmdb --dest /tmp/lsun_cat \\\n",
            "      --transform=center-crop-wide --width 512 --height=384\n",
            "\n",
            "Options:\n",
            "  --source PATH                   Directory or\n",
            "                                  archive name for\n",
            "                                  input dataset\n",
            "                                  [required]\n",
            "\n",
            "  --dest PATH                     Output directory\n",
            "                                  or archive name\n",
            "                                  for output\n",
            "                                  dataset\n",
            "                                  [required]\n",
            "\n",
            "  --max-images INTEGER            Output only up\n",
            "                                  to `max-images`\n",
            "                                  images\n",
            "\n",
            "  --resize-filter [box|lanczos]   Filter to use\n",
            "                                  when resizing\n",
            "                                  images for\n",
            "                                  output\n",
            "                                  resolution\n",
            "                                  [default:\n",
            "                                  lanczos]\n",
            "\n",
            "  --transform [center-crop|center-crop-wide]\n",
            "                                  Input\n",
            "                                  crop/resize mode\n",
            "\n",
            "  --width INTEGER                 Output width\n",
            "  --height INTEGER                Output height\n",
            "  --help                          Show this\n",
            "                                  message and\n",
            "                                  exit.\n"
          ]
        }
      ],
      "source": [
        "!python dataset_tool.py --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYsnSiRWUZi4",
        "outputId": "fc526496-8fd1-46eb-9b01-3f26adb363ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/833 [00:00<?, ?it/s]\r  0%|          | 4/833 [00:00<00:23, 35.43it/s]\r  2%|▏         | 13/833 [00:00<00:13, 60.37it/s]\r  2%|▏         | 20/833 [00:00<00:15, 53.50it/s]\r  3%|▎         | 26/833 [00:00<00:17, 46.44it/s]\r  4%|▎         | 31/833 [00:00<00:16, 47.31it/s]\r  4%|▍         | 36/833 [00:00<00:19, 39.89it/s]\r  5%|▍         | 41/833 [00:00<00:20, 38.17it/s]\r  5%|▌         | 45/833 [00:01<00:24, 32.18it/s]\r  6%|▋         | 53/833 [00:01<00:18, 42.42it/s]\r  7%|▋         | 58/833 [00:01<00:19, 39.44it/s]\r  8%|▊         | 63/833 [00:01<00:20, 37.10it/s]\r  8%|▊         | 67/833 [00:01<00:23, 32.48it/s]\r  9%|▊         | 71/833 [00:01<00:25, 29.63it/s]\r  9%|▉         | 75/833 [00:02<00:27, 27.72it/s]\r  9%|▉         | 78/833 [00:02<00:28, 26.41it/s]\r 10%|▉         | 82/833 [00:02<00:25, 29.19it/s]\r 10%|█         | 86/833 [00:02<00:27, 27.12it/s]\r 11%|█         | 89/833 [00:02<00:26, 27.72it/s]\r 11%|█▏        | 94/833 [00:02<00:24, 29.96it/s]\r 12%|█▏        | 98/833 [00:02<00:26, 27.49it/s]\r 12%|█▏        | 101/833 [00:03<00:27, 26.32it/s]\r 13%|█▎        | 105/833 [00:03<00:26, 27.06it/s]\r 13%|█▎        | 108/833 [00:03<00:28, 25.64it/s]\r 13%|█▎        | 112/833 [00:03<00:27, 26.40it/s]\r 14%|█▍        | 115/833 [00:03<00:28, 25.34it/s]\r 14%|█▍        | 118/833 [00:03<00:28, 24.86it/s]\r 15%|█▌        | 125/833 [00:03<00:21, 33.71it/s]\r 15%|█▌        | 129/833 [00:03<00:21, 32.73it/s]\r 16%|█▌        | 133/833 [00:04<00:22, 31.16it/s]\r 16%|█▋        | 137/833 [00:04<00:23, 30.07it/s]\r 17%|█▋        | 141/833 [00:04<00:23, 28.92it/s]\r 17%|█▋        | 144/833 [00:04<00:24, 28.51it/s]\r 18%|█▊        | 147/833 [00:04<00:24, 28.34it/s]\r 18%|█▊        | 150/833 [00:04<00:24, 27.82it/s]\r 18%|█▊        | 153/833 [00:04<00:25, 26.25it/s]\r 19%|█▉        | 158/833 [00:04<00:21, 31.92it/s]\r 19%|█▉        | 162/833 [00:05<00:19, 33.88it/s]\r 20%|█▉        | 166/833 [00:05<00:20, 32.91it/s]\r 21%|██        | 171/833 [00:05<00:18, 35.22it/s]\r 21%|██        | 175/833 [00:05<00:21, 30.31it/s]\r 21%|██▏       | 179/833 [00:05<00:22, 28.91it/s]\r 22%|██▏       | 182/833 [00:05<00:23, 27.42it/s]\r 22%|██▏       | 185/833 [00:05<00:24, 26.12it/s]\r 23%|██▎       | 188/833 [00:06<00:26, 24.58it/s]\r 23%|██▎       | 191/833 [00:06<00:26, 23.95it/s]\r 23%|██▎       | 194/833 [00:06<00:27, 23.44it/s]\r 24%|██▎       | 197/833 [00:06<00:27, 23.39it/s]\r 24%|██▍       | 200/833 [00:06<00:25, 24.36it/s]\r 24%|██▍       | 203/833 [00:06<00:26, 23.94it/s]\r 25%|██▍       | 208/833 [00:06<00:21, 29.09it/s]\r 26%|██▌       | 213/833 [00:06<00:19, 31.35it/s]\r 26%|██▋       | 219/833 [00:07<00:17, 35.99it/s]\r 27%|██▋       | 223/833 [00:07<00:17, 34.83it/s]\r 27%|██▋       | 227/833 [00:07<00:19, 31.54it/s]\r 28%|██▊       | 231/833 [00:07<00:18, 33.15it/s]\r 28%|██▊       | 235/833 [00:07<00:17, 34.55it/s]\r 29%|██▉       | 241/833 [00:07<00:14, 40.83it/s]\r 30%|██▉       | 246/833 [00:07<00:15, 38.04it/s]\r 30%|███       | 250/833 [00:07<00:16, 36.10it/s]\r 30%|███       | 254/833 [00:08<00:17, 32.42it/s]\r 31%|███       | 259/833 [00:08<00:16, 34.08it/s]\r 32%|███▏      | 266/833 [00:08<00:14, 39.50it/s]\r 33%|███▎      | 271/833 [00:08<00:16, 35.10it/s]\r 33%|███▎      | 275/833 [00:08<00:16, 33.27it/s]\r 34%|███▍      | 282/833 [00:08<00:13, 40.84it/s]\r 35%|███▍      | 289/833 [00:08<00:11, 47.84it/s]\r 35%|███▌      | 295/833 [00:09<00:12, 44.17it/s]\r 37%|███▋      | 305/833 [00:09<00:09, 57.47it/s]\r 37%|███▋      | 312/833 [00:09<00:08, 59.79it/s]\r 39%|███▊      | 321/833 [00:09<00:07, 65.41it/s]\r 39%|███▉      | 328/833 [00:09<00:09, 55.83it/s]\r 40%|████      | 335/833 [00:09<00:08, 59.04it/s]\r 41%|████      | 342/833 [00:09<00:10, 45.01it/s]\r 42%|████▏     | 348/833 [00:10<00:13, 35.46it/s]\r 42%|████▏     | 353/833 [00:10<00:14, 32.24it/s]\r 43%|████▎     | 357/833 [00:10<00:16, 29.68it/s]\r 43%|████▎     | 361/833 [00:10<00:17, 27.76it/s]\r 44%|████▍     | 365/833 [00:10<00:17, 26.44it/s]\r 44%|████▍     | 368/833 [00:11<00:18, 25.56it/s]\r 45%|████▍     | 371/833 [00:11<00:18, 24.98it/s]\r 45%|████▍     | 374/833 [00:11<00:18, 24.64it/s]\r 45%|████▌     | 378/833 [00:11<00:16, 27.38it/s]\r 46%|████▌     | 382/833 [00:11<00:15, 28.26it/s]\r 46%|████▋     | 387/833 [00:11<00:13, 32.11it/s]\r 47%|████▋     | 392/833 [00:11<00:13, 33.90it/s]\r 48%|████▊     | 396/833 [00:11<00:13, 32.59it/s]\r 48%|████▊     | 403/833 [00:11<00:10, 41.62it/s]\r 49%|████▉     | 409/833 [00:12<00:09, 43.55it/s]\r 50%|████▉     | 414/833 [00:12<00:09, 43.27it/s]\r 50%|█████     | 419/833 [00:12<00:10, 39.49it/s]\r 51%|█████     | 424/833 [00:12<00:09, 41.69it/s]\r 52%|█████▏    | 429/833 [00:12<00:09, 42.13it/s]\r 52%|█████▏    | 434/833 [00:12<00:11, 35.66it/s]\r 53%|█████▎    | 439/833 [00:12<00:10, 37.60it/s]\r 53%|█████▎    | 443/833 [00:13<00:11, 32.56it/s]\r 54%|█████▍    | 448/833 [00:13<00:11, 34.00it/s]\r 54%|█████▍    | 452/833 [00:13<00:10, 34.90it/s]\r 55%|█████▍    | 457/833 [00:13<00:09, 38.50it/s]\r 55%|█████▌    | 462/833 [00:13<00:09, 39.34it/s]\r 56%|█████▌    | 467/833 [00:13<00:09, 40.61it/s]\r 57%|█████▋    | 472/833 [00:13<00:09, 38.18it/s]\r 57%|█████▋    | 476/833 [00:13<00:10, 35.35it/s]\r 58%|█████▊    | 480/833 [00:14<00:10, 33.30it/s]\r 58%|█████▊    | 484/833 [00:14<00:11, 29.73it/s]\r 59%|█████▊    | 488/833 [00:14<00:12, 28.02it/s]\r 59%|█████▉    | 491/833 [00:14<00:12, 26.46it/s]\r 59%|█████▉    | 494/833 [00:14<00:13, 24.70it/s]\r 60%|█████▉    | 498/833 [00:14<00:12, 26.07it/s]\r 60%|██████    | 501/833 [00:14<00:13, 24.41it/s]\r 61%|██████    | 504/833 [00:15<00:13, 24.08it/s]\r 61%|██████    | 507/833 [00:15<00:13, 23.90it/s]\r 61%|██████▏   | 511/833 [00:15<00:12, 25.49it/s]\r 62%|██████▏   | 514/833 [00:15<00:12, 24.56it/s]\r 62%|██████▏   | 517/833 [00:15<00:13, 24.19it/s]\r 62%|██████▏   | 520/833 [00:15<00:13, 24.02it/s]\r 63%|██████▎   | 524/833 [00:15<00:12, 25.48it/s]\r 63%|██████▎   | 527/833 [00:16<00:12, 24.63it/s]\r 64%|██████▎   | 530/833 [00:16<00:12, 23.85it/s]\r 64%|██████▍   | 534/833 [00:16<00:10, 27.26it/s]\r 64%|██████▍   | 537/833 [00:16<00:11, 26.15it/s]\r 65%|██████▍   | 540/833 [00:16<00:11, 24.87it/s]\r 65%|██████▌   | 544/833 [00:16<00:11, 26.15it/s]\r 66%|██████▌   | 547/833 [00:16<00:11, 25.20it/s]\r 66%|██████▌   | 550/833 [00:16<00:11, 23.68it/s]\r 66%|██████▋   | 553/833 [00:17<00:11, 23.45it/s]\r 67%|██████▋   | 556/833 [00:17<00:12, 23.04it/s]\r 67%|██████▋   | 559/833 [00:17<00:11, 23.10it/s]\r 67%|██████▋   | 562/833 [00:17<00:11, 22.73it/s]\r 68%|██████▊   | 565/833 [00:17<00:11, 22.69it/s]\r 68%|██████▊   | 568/833 [00:17<00:11, 22.81it/s]\r 69%|██████▊   | 571/833 [00:17<00:11, 22.14it/s]\r 69%|██████▉   | 574/833 [00:18<00:11, 22.42it/s]\r 69%|██████▉   | 577/833 [00:18<00:11, 22.09it/s]\r 70%|██████▉   | 581/833 [00:18<00:10, 24.25it/s]\r 70%|███████   | 584/833 [00:18<00:10, 24.08it/s]\r 70%|███████   | 587/833 [00:18<00:10, 23.34it/s]\r 71%|███████   | 591/833 [00:18<00:09, 26.88it/s]\r 71%|███████▏  | 594/833 [00:18<00:09, 25.79it/s]\r 72%|███████▏  | 597/833 [00:18<00:09, 25.10it/s]\r 72%|███████▏  | 600/833 [00:19<00:10, 22.41it/s]\r 72%|███████▏  | 603/833 [00:19<00:10, 22.60it/s]\r 73%|███████▎  | 607/833 [00:19<00:08, 26.43it/s]\r 73%|███████▎  | 610/833 [00:19<00:08, 25.43it/s]\r 74%|███████▎  | 613/833 [00:19<00:09, 23.22it/s]\r 74%|███████▍  | 616/833 [00:19<00:09, 23.39it/s]\r 74%|███████▍  | 619/833 [00:19<00:09, 23.24it/s]\r 75%|███████▍  | 622/833 [00:20<00:09, 23.25it/s]\r 75%|███████▌  | 625/833 [00:20<00:08, 23.22it/s]\r 76%|███████▌  | 629/833 [00:20<00:08, 24.86it/s]\r 76%|███████▌  | 633/833 [00:20<00:07, 28.11it/s]\r 76%|███████▋  | 637/833 [00:20<00:06, 30.96it/s]\r 77%|███████▋  | 643/833 [00:20<00:05, 35.98it/s]\r 78%|███████▊  | 647/833 [00:20<00:05, 33.55it/s]\r 78%|███████▊  | 651/833 [00:20<00:05, 34.66it/s]\r 79%|███████▉  | 658/833 [00:20<00:04, 43.53it/s]\r 80%|███████▉  | 663/833 [00:21<00:03, 43.51it/s]\r 80%|████████  | 670/833 [00:21<00:03, 48.12it/s]\r 81%|████████  | 675/833 [00:21<00:03, 44.00it/s]\r 82%|████████▏ | 680/833 [00:21<00:04, 35.13it/s]\r 82%|████████▏ | 684/833 [00:21<00:04, 30.76it/s]\r 83%|████████▎ | 688/833 [00:21<00:05, 28.47it/s]\r 83%|████████▎ | 692/833 [00:22<00:04, 28.51it/s]\r 84%|████████▎ | 696/833 [00:22<00:04, 29.54it/s]\r 84%|████████▍ | 700/833 [00:22<00:04, 31.38it/s]\r 85%|████████▍ | 704/833 [00:22<00:04, 30.78it/s]\r 85%|████████▌ | 709/833 [00:22<00:03, 32.72it/s]\r 86%|████████▌ | 713/833 [00:22<00:03, 33.63it/s]\r 87%|████████▋ | 721/833 [00:22<00:02, 44.64it/s]\r 88%|████████▊ | 730/833 [00:22<00:01, 55.91it/s]\r 88%|████████▊ | 736/833 [00:23<00:02, 43.40it/s]\r 89%|████████▉ | 741/833 [00:23<00:02, 40.21it/s]\r 90%|████████▉ | 746/833 [00:23<00:02, 33.87it/s]\r 90%|█████████ | 750/833 [00:23<00:02, 33.36it/s]\r 91%|█████████ | 756/833 [00:23<00:02, 38.40it/s]\r 91%|█████████▏| 761/833 [00:23<00:01, 36.99it/s]\r 92%|█████████▏| 766/833 [00:23<00:01, 38.78it/s]\r 93%|█████████▎| 771/833 [00:24<00:01, 37.36it/s]\r 93%|█████████▎| 775/833 [00:24<00:01, 33.93it/s]\r 94%|█████████▎| 779/833 [00:24<00:01, 34.39it/s]\r 95%|█████████▍| 789/833 [00:24<00:00, 49.39it/s]\r 95%|█████████▌| 795/833 [00:24<00:00, 43.21it/s]\r 96%|█████████▌| 800/833 [00:24<00:00, 36.58it/s]\r 97%|█████████▋| 805/833 [00:24<00:00, 35.98it/s]\r 97%|█████████▋| 810/833 [00:25<00:00, 38.85it/s]\r 98%|█████████▊| 815/833 [00:25<00:00, 37.98it/s]\r 99%|█████████▊| 821/833 [00:25<00:00, 39.45it/s]\r 99%|█████████▉| 826/833 [00:25<00:00, 39.69it/s]\r100%|█████████▉| 831/833 [00:25<00:00, 38.75it/s]\r100%|██████████| 833/833 [00:25<00:00, 32.47it/s]\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "python dataset_tool.py --source=./data/pokemon --dest=./data/pokemon256.zip \\\n",
        "  --width=256 --height=256 --transform=center-crop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9utxXbvZais4",
        "outputId": "9fc7bd04-c63e-4ff6-955a-70d741b4bde5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "1.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n",
        "!python -c 'import torch; print(torch.__version__) '"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6ClR6v6aTus",
        "outputId": "5ccffda9-5729-4c6f-b44f-ae2cf773de7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch==1.8.0\n",
            "  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 735.5 MB 14 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.0\n",
            "  Downloading torchvision-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 110 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.8.0\n",
            "  Downloading torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 53.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.10.0+cu111\n",
            "    Uninstalling torchaudio-0.10.0+cu111:\n",
            "      Successfully uninstalled torchaudio-0.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0 torchaudio-0.8.0 torchvision-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqT9n6W2t42n",
        "outputId": "2ab512dc-e21f-426e-f1fb-1c7ee8847b12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading networks from \"/content/drive/MyDrive/Major_Experiment_B/stylegan2_ada_retraining-runs_/00000-pokemon256-auto1-kimg1000-resumecustom/network-snapshot-000600.pkl\"...\n",
            "warn: --class=lbl ignored when running on an unconditional network\n",
            "Generating image for seed 0 (0/36) ...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "Generating image for seed 1 (1/36) ...\n",
            "Generating image for seed 2 (2/36) ...\n",
            "Generating image for seed 3 (3/36) ...\n",
            "Generating image for seed 4 (4/36) ...\n",
            "Generating image for seed 5 (5/36) ...\n",
            "Generating image for seed 6 (6/36) ...\n",
            "Generating image for seed 7 (7/36) ...\n",
            "Generating image for seed 8 (8/36) ...\n",
            "Generating image for seed 9 (9/36) ...\n",
            "Generating image for seed 10 (10/36) ...\n",
            "Generating image for seed 11 (11/36) ...\n",
            "Generating image for seed 12 (12/36) ...\n",
            "Generating image for seed 13 (13/36) ...\n",
            "Generating image for seed 14 (14/36) ...\n",
            "Generating image for seed 15 (15/36) ...\n",
            "Generating image for seed 16 (16/36) ...\n",
            "Generating image for seed 17 (17/36) ...\n",
            "Generating image for seed 18 (18/36) ...\n",
            "Generating image for seed 19 (19/36) ...\n",
            "Generating image for seed 20 (20/36) ...\n",
            "Generating image for seed 21 (21/36) ...\n",
            "Generating image for seed 22 (22/36) ...\n",
            "Generating image for seed 23 (23/36) ...\n",
            "Generating image for seed 24 (24/36) ...\n",
            "Generating image for seed 25 (25/36) ...\n",
            "Generating image for seed 26 (26/36) ...\n",
            "Generating image for seed 27 (27/36) ...\n",
            "Generating image for seed 28 (28/36) ...\n",
            "Generating image for seed 29 (29/36) ...\n",
            "Generating image for seed 30 (30/36) ...\n",
            "Generating image for seed 31 (31/36) ...\n",
            "Generating image for seed 32 (32/36) ...\n",
            "Generating image for seed 33 (33/36) ...\n",
            "Generating image for seed 34 (34/36) ...\n",
            "Generating image for seed 35 (35/36) ...\n"
          ]
        }
      ],
      "source": [
        "!python generate.py --outdir=outdir --seeds=85,265,297 \\\n",
        "    --network=pretrain_network.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HQx2e16s7qC",
        "outputId": "7909a5a3-5ebf-4268-c596-b44af914c067"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usage: train.py [OPTIONS]\n",
            "\n",
            "  Train a GAN using the techniques described in\n",
            "  the paper \"Training Generative Adversarial\n",
            "  Networks with Limited Data\".\n",
            "\n",
            "  Examples:\n",
            "\n",
            "  # Train with custom dataset using 1 GPU.\n",
            "  python train.py --outdir=~/training-runs --data=~/mydataset.zip --gpus=1\n",
            "\n",
            "  # Train class-conditional CIFAR-10 using 2 GPUs.\n",
            "  python train.py --outdir=~/training-runs --data=~/datasets/cifar10.zip \\\n",
            "      --gpus=2 --cfg=cifar --cond=1\n",
            "\n",
            "  # Transfer learn MetFaces from FFHQ using 4 GPUs.\n",
            "  python train.py --outdir=~/training-runs --data=~/datasets/metfaces.zip \\\n",
            "      --gpus=4 --cfg=paper1024 --mirror=1 --resume=ffhq1024 --snap=10\n",
            "\n",
            "  # Reproduce original StyleGAN2 config F.\n",
            "  python train.py --outdir=~/training-runs --data=~/datasets/ffhq.zip \\\n",
            "      --gpus=8 --cfg=stylegan2 --mirror=1 --aug=noaug\n",
            "\n",
            "  Base configs (--cfg):\n",
            "    auto       Automatically select reasonable defaults based on resolution\n",
            "               and GPU count. Good starting point for new datasets.\n",
            "    stylegan2  Reproduce results for StyleGAN2 config F at 1024x1024.\n",
            "    paper256   Reproduce results for FFHQ and LSUN Cat at 256x256.\n",
            "    paper512   Reproduce results for BreCaHAD and AFHQ at 512x512.\n",
            "    paper1024  Reproduce results for MetFaces at 1024x1024.\n",
            "    cifar      Reproduce results for CIFAR-10 at 32x32.\n",
            "\n",
            "  Transfer learning source networks (--resume):\n",
            "    ffhq256        FFHQ trained at 256x256 resolution.\n",
            "    ffhq512        FFHQ trained at 512x512 resolution.\n",
            "    ffhq1024       FFHQ trained at 1024x1024 resolution.\n",
            "    celebahq256    CelebA-HQ trained at 256x256 resolution.\n",
            "    lsundog256     LSUN Dog trained at 256x256 resolution.\n",
            "    <PATH or URL>  Custom network pickle.\n",
            "\n",
            "Options:\n",
            "  --outdir DIR                    Where to save\n",
            "                                  the results\n",
            "                                  [required]\n",
            "\n",
            "  --gpus INT                      Number of GPUs\n",
            "                                  to use [default:\n",
            "                                  1]\n",
            "\n",
            "  --snap INT                      Snapshot\n",
            "                                  interval\n",
            "                                  [default: 50\n",
            "                                  ticks]\n",
            "\n",
            "  --metrics LIST                  Comma-separated\n",
            "                                  list or \"none\"\n",
            "                                  [default:\n",
            "                                  fid50k_full]\n",
            "\n",
            "  --seed INT                      Random seed\n",
            "                                  [default: 0]\n",
            "\n",
            "  -n, --dry-run                   Print training\n",
            "                                  options and exit\n",
            "\n",
            "  --data PATH                     Training data\n",
            "                                  (directory or\n",
            "                                  zip)  [required]\n",
            "\n",
            "  --cond BOOL                     Train\n",
            "                                  conditional\n",
            "                                  model based on\n",
            "                                  dataset labels\n",
            "                                  [default: false]\n",
            "\n",
            "  --subset INT                    Train with only\n",
            "                                  N images\n",
            "                                  [default: all]\n",
            "\n",
            "  --mirror BOOL                   Enable dataset\n",
            "                                  x-flips\n",
            "                                  [default: false]\n",
            "\n",
            "  --cfg [auto|stylegan2|paper256|paper512|paper1024|cifar]\n",
            "                                  Base config\n",
            "                                  [default: auto]\n",
            "\n",
            "  --gamma FLOAT                   Override R1\n",
            "                                  gamma\n",
            "\n",
            "  --kimg INT                      Override\n",
            "                                  training\n",
            "                                  duration\n",
            "\n",
            "  --batch INT                     Override batch\n",
            "                                  size\n",
            "\n",
            "  --aug [noaug|ada|fixed]         Augmentation\n",
            "                                  mode [default:\n",
            "                                  ada]\n",
            "\n",
            "  --p FLOAT                       Augmentation\n",
            "                                  probability for\n",
            "                                  --aug=fixed\n",
            "\n",
            "  --target FLOAT                  ADA target value\n",
            "                                  for --aug=ada\n",
            "\n",
            "  --augpipe [blit|geom|color|filter|noise|cutout|bg|bgc|bgcf|bgcfn|bgcfnc]\n",
            "                                  Augmentation\n",
            "                                  pipeline\n",
            "                                  [default: bgc]\n",
            "\n",
            "  --resume PKL                    Resume training\n",
            "                                  [default:\n",
            "                                  noresume]\n",
            "\n",
            "  --freezed INT                   Freeze-D\n",
            "                                  [default: 0\n",
            "                                  layers]\n",
            "\n",
            "  --fp32 BOOL                     Disable mixed-\n",
            "                                  precision\n",
            "                                  training\n",
            "\n",
            "  --nhwc BOOL                     Use NHWC memory\n",
            "                                  format with FP16\n",
            "\n",
            "  --nobench BOOL                  Disable cuDNN\n",
            "                                  benchmarking\n",
            "\n",
            "  --allow-tf32 BOOL               Allow PyTorch to\n",
            "                                  use TF32\n",
            "                                  internally\n",
            "\n",
            "  --workers INT                   Override number\n",
            "                                  of DataLoader\n",
            "                                  workers\n",
            "\n",
            "  --help                          Show this\n",
            "                                  message and\n",
            "                                  exit.\n"
          ]
        }
      ],
      "source": [
        "!python train.py --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqQ_ArldH4OW",
        "outputId": "1dc34e0a-3873-464f-b16f-dcf16e78ddd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/stylegan2-ada-pytorch/data/pokemon256.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 833,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 256\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 3,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 16384,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 0.8192\n",
            "  },\n",
            "  \"total_kimg\": 1000,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"ema_rampup\": null,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/Major_Experiment_B/stylegan2_ada_retraining-runs_/00000-pokemon256-auto1-kimg1000-resumecustom/network-snapshot-000600.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/Major_Experiment_B/stylegan2_ada_retraining-runs_2/00000-pokemon256-auto1-kimg1000-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:   /content/drive/MyDrive/Major_Experiment_B/stylegan2_ada_retraining-runs_2/00000-pokemon256-auto1-kimg1000-resumecustom\n",
            "Training data:      /content/stylegan2-ada-pytorch/data/pokemon256.zip\n",
            "Training duration:  1000 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   833\n",
            "Image resolution:   256\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "Num images:  833\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"/content/drive/MyDrive/Major_Experiment_B/stylegan2_ada_retraining-runs_/00000-pokemon256-auto1-kimg1000-resumecustom/network-snapshot-000600.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Generator             Parameters  Buffers  Output shape         Datatype\n",
            "---                   ---         ---      ---                  ---     \n",
            "mapping.fc0           262656      -        [16, 512]            float32 \n",
            "mapping.fc1           262656      -        [16, 512]            float32 \n",
            "mapping               -           512      [16, 14, 512]        float32 \n",
            "synthesis.b4.conv1    2622465     32       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4.torgb    264195      -        [16, 3, 4, 4]        float32 \n",
            "synthesis.b4:0        8192        16       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4:1        -           -        [16, 512, 4, 4]      float32 \n",
            "synthesis.b8.conv0    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.conv1    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.torgb    264195      -        [16, 3, 8, 8]        float32 \n",
            "synthesis.b8:0        -           16       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8:1        -           -        [16, 512, 8, 8]      float32 \n",
            "synthesis.b16.conv0   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.conv1   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.torgb   264195      -        [16, 3, 16, 16]      float32 \n",
            "synthesis.b16:0       -           16       [16, 512, 16, 16]    float32 \n",
            "synthesis.b16:1       -           -        [16, 512, 16, 16]    float32 \n",
            "synthesis.b32.conv0   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.conv1   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.torgb   264195      -        [16, 3, 32, 32]      float16 \n",
            "synthesis.b32:0       -           16       [16, 512, 32, 32]    float16 \n",
            "synthesis.b32:1       -           -        [16, 512, 32, 32]    float32 \n",
            "synthesis.b64.conv0   1442561     4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.conv1   721409      4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.torgb   132099      -        [16, 3, 64, 64]      float16 \n",
            "synthesis.b64:0       -           16       [16, 256, 64, 64]    float16 \n",
            "synthesis.b64:1       -           -        [16, 256, 64, 64]    float32 \n",
            "synthesis.b128.conv0  426369      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.conv1  213249      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.torgb  66051       -        [16, 3, 128, 128]    float16 \n",
            "synthesis.b128:0      -           16       [16, 128, 128, 128]  float16 \n",
            "synthesis.b128:1      -           -        [16, 128, 128, 128]  float32 \n",
            "synthesis.b256.conv0  139457      65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.conv1  69761       65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.torgb  33027       -        [16, 3, 256, 256]    float16 \n",
            "synthesis.b256:0      -           16       [16, 64, 256, 256]   float16 \n",
            "synthesis.b256:1      -           -        [16, 64, 256, 256]   float32 \n",
            "---                   ---         ---      ---                  ---     \n",
            "Total                 23191522    175568   -                    -       \n",
            "\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   256         16       [16, 64, 256, 256]   float16 \n",
            "b256.skip      8192        16       [16, 128, 128, 128]  float16 \n",
            "b256.conv0     36928       16       [16, 64, 256, 256]   float16 \n",
            "b256.conv1     73856       16       [16, 128, 128, 128]  float16 \n",
            "b256           -           16       [16, 128, 128, 128]  float16 \n",
            "b128.skip      32768       16       [16, 256, 64, 64]    float16 \n",
            "b128.conv0     147584      16       [16, 128, 128, 128]  float16 \n",
            "b128.conv1     295168      16       [16, 256, 64, 64]    float16 \n",
            "b128           -           16       [16, 256, 64, 64]    float16 \n",
            "b64.skip       131072      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      590080      16       [16, 256, 64, 64]    float16 \n",
            "b64.conv1      1180160     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          24001089    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 1000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 44s          sec/tick 8.8     sec/kimg 550.87  maintenance 35.5   cpumem 4.71   gpumem 12.63  augment 0.000\n",
            "Evaluating metrics...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "{\"results\": {\"fid50k_full\": 68.26419683505284}, \"metric\": \"fid50k_full\", \"total_time\": 603.6958875656128, \"total_time_str\": \"10m 04s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1643895193.1269617}\n",
            "tick 1     kimg 4.0      time 15m 28s      sec/tick 265.3   sec/kimg 66.31   maintenance 618.4  cpumem 5.19   gpumem 9.39   augment 0.036\n",
            "tick 2     kimg 8.0      time 19m 54s      sec/tick 266.3   sec/kimg 66.56   maintenance 0.2    cpumem 5.19   gpumem 5.38   augment 0.072\n",
            "tick 3     kimg 12.0     time 24m 20s      sec/tick 265.7   sec/kimg 66.42   maintenance 0.2    cpumem 5.19   gpumem 5.40   augment 0.108\n",
            "tick 4     kimg 16.0     time 28m 47s      sec/tick 266.6   sec/kimg 66.65   maintenance 0.2    cpumem 5.19   gpumem 5.43   augment 0.146\n",
            "tick 5     kimg 20.0     time 33m 13s      sec/tick 266.3   sec/kimg 66.58   maintenance 0.2    cpumem 5.19   gpumem 5.43   augment 0.180\n",
            "tick 6     kimg 24.0     time 37m 40s      sec/tick 266.4   sec/kimg 66.60   maintenance 0.2    cpumem 5.19   gpumem 5.45   augment 0.214\n",
            "tick 7     kimg 28.0     time 42m 07s      sec/tick 266.5   sec/kimg 66.62   maintenance 0.2    cpumem 5.19   gpumem 5.43   augment 0.252\n",
            "tick 8     kimg 32.0     time 46m 34s      sec/tick 266.9   sec/kimg 66.73   maintenance 0.2    cpumem 5.19   gpumem 5.49   augment 0.285\n",
            "tick 9     kimg 36.0     time 51m 00s      sec/tick 266.3   sec/kimg 66.58   maintenance 0.2    cpumem 5.19   gpumem 5.50   augment 0.318\n",
            "tick 10    kimg 40.0     time 55m 28s      sec/tick 267.2   sec/kimg 66.80   maintenance 0.2    cpumem 5.19   gpumem 5.50   augment 0.351\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 67.02857132429081}, \"metric\": \"fid50k_full\", \"total_time\": 591.1711139678955, \"total_time_str\": \"9m 51s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000040.pkl\", \"timestamp\": 1643898464.7153263}\n",
            "tick 11    kimg 44.0     time 1h 10m 01s   sec/tick 266.6   sec/kimg 66.65   maintenance 606.5  cpumem 5.54   gpumem 5.49   augment 0.385\n",
            "tick 12    kimg 48.0     time 1h 14m 28s   sec/tick 267.3   sec/kimg 66.83   maintenance 0.2    cpumem 5.54   gpumem 5.46   augment 0.419\n",
            "tick 13    kimg 52.0     time 1h 18m 56s   sec/tick 267.0   sec/kimg 66.76   maintenance 0.2    cpumem 5.54   gpumem 5.53   augment 0.449\n",
            "tick 14    kimg 56.0     time 1h 23m 23s   sec/tick 267.0   sec/kimg 66.75   maintenance 0.2    cpumem 5.54   gpumem 5.50   augment 0.477\n",
            "tick 15    kimg 60.0     time 1h 27m 50s   sec/tick 267.2   sec/kimg 66.80   maintenance 0.2    cpumem 5.54   gpumem 5.51   augment 0.509\n",
            "tick 16    kimg 64.0     time 1h 32m 18s   sec/tick 267.6   sec/kimg 66.90   maintenance 0.2    cpumem 5.54   gpumem 5.49   augment 0.542\n",
            "tick 17    kimg 68.0     time 1h 36m 45s   sec/tick 266.9   sec/kimg 66.74   maintenance 0.2    cpumem 5.52   gpumem 5.49   augment 0.569\n",
            "tick 18    kimg 72.0     time 1h 41m 13s   sec/tick 267.8   sec/kimg 66.96   maintenance 0.2    cpumem 5.52   gpumem 5.56   augment 0.593\n",
            "tick 19    kimg 76.0     time 1h 45m 40s   sec/tick 267.2   sec/kimg 66.81   maintenance 0.2    cpumem 5.52   gpumem 5.52   augment 0.620\n",
            "tick 20    kimg 80.0     time 1h 50m 09s   sec/tick 268.0   sec/kimg 67.00   maintenance 0.2    cpumem 5.52   gpumem 5.51   augment 0.650\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 52.66625922867295}, \"metric\": \"fid50k_full\", \"total_time\": 594.4573347568512, \"total_time_str\": \"9m 54s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000080.pkl\", \"timestamp\": 1643901748.72052}\n",
            "tick 21    kimg 84.0     time 2h 04m 46s   sec/tick 267.7   sec/kimg 66.93   maintenance 609.6  cpumem 5.12   gpumem 5.50   augment 0.679\n",
            "tick 22    kimg 88.0     time 2h 09m 14s   sec/tick 267.8   sec/kimg 66.94   maintenance 0.2    cpumem 5.12   gpumem 5.53   augment 0.705\n",
            "tick 23    kimg 92.0     time 2h 13m 42s   sec/tick 267.9   sec/kimg 66.97   maintenance 0.2    cpumem 5.12   gpumem 5.55   augment 0.724\n",
            "tick 24    kimg 96.0     time 2h 18m 10s   sec/tick 268.3   sec/kimg 67.08   maintenance 0.2    cpumem 5.11   gpumem 5.56   augment 0.742\n",
            "tick 25    kimg 100.0    time 2h 22m 38s   sec/tick 267.4   sec/kimg 66.86   maintenance 0.2    cpumem 5.11   gpumem 5.55   augment 0.760\n",
            "tick 26    kimg 104.0    time 2h 27m 07s   sec/tick 268.2   sec/kimg 67.06   maintenance 0.2    cpumem 5.11   gpumem 5.52   augment 0.785\n",
            "tick 27    kimg 108.0    time 2h 31m 34s   sec/tick 267.6   sec/kimg 66.91   maintenance 0.2    cpumem 5.11   gpumem 5.52   augment 0.808\n",
            "tick 28    kimg 112.0    time 2h 36m 03s   sec/tick 268.6   sec/kimg 67.15   maintenance 0.2    cpumem 5.11   gpumem 5.58   augment 0.829\n",
            "tick 29    kimg 116.0    time 2h 40m 31s   sec/tick 268.1   sec/kimg 67.02   maintenance 0.2    cpumem 5.11   gpumem 5.55   augment 0.851\n",
            "tick 30    kimg 120.0    time 2h 45m 00s   sec/tick 268.2   sec/kimg 67.05   maintenance 0.2    cpumem 5.11   gpumem 5.57   augment 0.863\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 53.00836132907685}, \"metric\": \"fid50k_full\", \"total_time\": 588.3557574748993, \"total_time_str\": \"9m 48s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000120.pkl\", \"timestamp\": 1643905032.1654873}\n",
            "tick 31    kimg 124.0    time 2h 59m 30s   sec/tick 268.1   sec/kimg 67.03   maintenance 601.9  cpumem 5.49   gpumem 5.60   augment 0.882\n",
            "tick 32    kimg 128.0    time 3h 03m 58s   sec/tick 268.5   sec/kimg 67.13   maintenance 0.2    cpumem 5.49   gpumem 5.57   augment 0.903\n",
            "tick 33    kimg 132.0    time 3h 08m 26s   sec/tick 267.8   sec/kimg 66.94   maintenance 0.2    cpumem 5.49   gpumem 5.55   augment 0.912\n",
            "tick 34    kimg 136.0    time 3h 12m 55s   sec/tick 268.5   sec/kimg 67.13   maintenance 0.2    cpumem 5.49   gpumem 5.58   augment 0.933\n",
            "tick 35    kimg 140.0    time 3h 17m 23s   sec/tick 267.8   sec/kimg 66.95   maintenance 0.2    cpumem 5.49   gpumem 5.58   augment 0.952\n",
            "tick 36    kimg 144.0    time 3h 21m 52s   sec/tick 268.6   sec/kimg 67.16   maintenance 0.2    cpumem 5.49   gpumem 5.57   augment 0.964\n",
            "tick 37    kimg 148.0    time 3h 26m 20s   sec/tick 268.2   sec/kimg 67.06   maintenance 0.2    cpumem 5.49   gpumem 5.57   augment 0.979\n",
            "tick 38    kimg 152.0    time 3h 30m 49s   sec/tick 268.3   sec/kimg 67.07   maintenance 0.2    cpumem 5.49   gpumem 5.56   augment 0.996\n",
            "tick 39    kimg 156.0    time 3h 35m 17s   sec/tick 268.3   sec/kimg 67.06   maintenance 0.2    cpumem 5.49   gpumem 5.59   augment 1.011\n",
            "tick 40    kimg 160.0    time 3h 39m 46s   sec/tick 268.6   sec/kimg 67.14   maintenance 0.2    cpumem 5.49   gpumem 5.57   augment 1.027\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 56.33659457576775}, \"metric\": \"fid50k_full\", \"total_time\": 588.5460729598999, \"total_time_str\": \"9m 49s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000160.pkl\", \"timestamp\": 1643908319.9820476}\n",
            "tick 41    kimg 164.0    time 3h 54m 17s   sec/tick 267.7   sec/kimg 66.93   maintenance 603.5  cpumem 5.50   gpumem 5.56   augment 1.039\n",
            "tick 42    kimg 168.0    time 3h 58m 46s   sec/tick 268.6   sec/kimg 67.15   maintenance 0.2    cpumem 5.50   gpumem 5.58   augment 1.059\n",
            "tick 43    kimg 172.0    time 4h 03m 14s   sec/tick 267.8   sec/kimg 66.95   maintenance 0.2    cpumem 5.50   gpumem 5.56   augment 1.077\n",
            "tick 44    kimg 176.0    time 4h 07m 43s   sec/tick 268.5   sec/kimg 67.14   maintenance 0.2    cpumem 5.50   gpumem 5.59   augment 1.091\n",
            "tick 45    kimg 180.0    time 4h 12m 11s   sec/tick 268.2   sec/kimg 67.05   maintenance 0.2    cpumem 5.50   gpumem 5.57   augment 1.111\n",
            "tick 46    kimg 184.0    time 4h 16m 39s   sec/tick 268.1   sec/kimg 67.03   maintenance 0.2    cpumem 5.50   gpumem 5.56   augment 1.125\n",
            "tick 47    kimg 188.0    time 4h 21m 08s   sec/tick 268.2   sec/kimg 67.06   maintenance 0.2    cpumem 5.50   gpumem 5.59   augment 1.139\n",
            "tick 48    kimg 192.0    time 4h 25m 37s   sec/tick 268.6   sec/kimg 67.15   maintenance 0.2    cpumem 5.51   gpumem 5.58   augment 1.154\n",
            "tick 49    kimg 196.0    time 4h 30m 05s   sec/tick 267.8   sec/kimg 66.95   maintenance 0.2    cpumem 5.51   gpumem 5.60   augment 1.166\n",
            "tick 50    kimg 200.0    time 4h 34m 33s   sec/tick 268.6   sec/kimg 67.15   maintenance 0.2    cpumem 5.51   gpumem 5.59   augment 1.180\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 64.08357631767817}, \"metric\": \"fid50k_full\", \"total_time\": 588.1689355373383, \"total_time_str\": \"9m 48s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000200.pkl\", \"timestamp\": 1643911607.6720438}\n",
            "tick 51    kimg 204.0    time 4h 49m 05s   sec/tick 267.9   sec/kimg 66.98   maintenance 603.8  cpumem 5.49   gpumem 5.57   augment 1.203\n",
            "tick 52    kimg 208.0    time 4h 53m 34s   sec/tick 268.7   sec/kimg 67.19   maintenance 0.2    cpumem 5.49   gpumem 5.59   augment 1.227\n",
            "tick 53    kimg 212.0    time 4h 58m 02s   sec/tick 268.2   sec/kimg 67.06   maintenance 0.2    cpumem 5.49   gpumem 5.57   augment 1.246\n",
            "tick 54    kimg 216.0    time 5h 02m 31s   sec/tick 268.3   sec/kimg 67.08   maintenance 0.2    cpumem 5.49   gpumem 5.57   augment 1.266\n",
            "tick 55    kimg 220.0    time 5h 07m 00s   sec/tick 268.4   sec/kimg 67.09   maintenance 0.2    cpumem 5.49   gpumem 5.63   augment 1.286\n",
            "tick 56    kimg 224.0    time 5h 11m 28s   sec/tick 268.7   sec/kimg 67.17   maintenance 0.2    cpumem 5.49   gpumem 5.57   augment 1.307\n",
            "tick 57    kimg 228.0    time 5h 15m 57s   sec/tick 268.0   sec/kimg 66.99   maintenance 0.2    cpumem 5.49   gpumem 5.62   augment 1.324\n",
            "tick 58    kimg 232.0    time 5h 20m 26s   sec/tick 268.8   sec/kimg 67.19   maintenance 0.2    cpumem 5.49   gpumem 5.58   augment 1.347\n",
            "tick 59    kimg 236.0    time 5h 24m 54s   sec/tick 267.9   sec/kimg 66.99   maintenance 0.2    cpumem 5.49   gpumem 5.61   augment 1.364\n",
            "tick 60    kimg 240.0    time 5h 29m 22s   sec/tick 268.6   sec/kimg 67.14   maintenance 0.2    cpumem 5.49   gpumem 5.56   augment 1.386\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 65.10455225885772}, \"metric\": \"fid50k_full\", \"total_time\": 585.6319897174835, \"total_time_str\": \"9m 46s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000240.pkl\", \"timestamp\": 1643914893.614225}\n",
            "tick 61    kimg 244.0    time 5h 43m 52s   sec/tick 268.4   sec/kimg 67.10   maintenance 600.7  cpumem 5.36   gpumem 5.55   augment 1.406\n",
            "tick 62    kimg 248.0    time 5h 48m 20s   sec/tick 268.3   sec/kimg 67.09   maintenance 0.2    cpumem 5.36   gpumem 5.59   augment 1.426\n",
            "tick 63    kimg 252.0    time 5h 52m 49s   sec/tick 268.4   sec/kimg 67.11   maintenance 0.2    cpumem 5.36   gpumem 5.60   augment 1.440\n",
            "tick 64    kimg 256.0    time 5h 57m 18s   sec/tick 268.7   sec/kimg 67.19   maintenance 0.2    cpumem 5.36   gpumem 5.59   augment 1.453\n",
            "tick 65    kimg 260.0    time 6h 01m 46s   sec/tick 268.0   sec/kimg 67.00   maintenance 0.2    cpumem 5.36   gpumem 5.57   augment 1.464\n",
            "tick 66    kimg 264.0    time 6h 06m 15s   sec/tick 268.7   sec/kimg 67.18   maintenance 0.2    cpumem 5.36   gpumem 5.57   augment 1.481\n",
            "tick 67    kimg 268.0    time 6h 10m 43s   sec/tick 268.0   sec/kimg 67.00   maintenance 0.2    cpumem 5.36   gpumem 5.61   augment 1.495\n",
            "tick 68    kimg 272.0    time 6h 15m 12s   sec/tick 268.8   sec/kimg 67.19   maintenance 0.2    cpumem 5.36   gpumem 5.59   augment 1.516\n",
            "tick 69    kimg 276.0    time 6h 19m 40s   sec/tick 268.4   sec/kimg 67.09   maintenance 0.2    cpumem 5.36   gpumem 5.58   augment 1.533\n",
            "tick 70    kimg 280.0    time 6h 24m 09s   sec/tick 268.4   sec/kimg 67.09   maintenance 0.2    cpumem 5.36   gpumem 5.61   augment 1.551\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 70.4172809364492}, \"metric\": \"fid50k_full\", \"total_time\": 589.7971441745758, \"total_time_str\": \"9m 50s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000280.pkl\", \"timestamp\": 1643918185.0079997}\n",
            "tick 71    kimg 284.0    time 6h 38m 43s   sec/tick 268.4   sec/kimg 67.09   maintenance 605.6  cpumem 5.40   gpumem 5.57   augment 1.571\n",
            "tick 72    kimg 288.0    time 6h 43m 12s   sec/tick 268.7   sec/kimg 67.18   maintenance 0.2    cpumem 5.40   gpumem 5.61   augment 1.589\n",
            "tick 73    kimg 292.0    time 6h 47m 40s   sec/tick 268.0   sec/kimg 66.99   maintenance 0.2    cpumem 5.40   gpumem 5.59   augment 1.610\n",
            "tick 74    kimg 296.0    time 6h 52m 09s   sec/tick 268.7   sec/kimg 67.18   maintenance 0.2    cpumem 5.38   gpumem 5.60   augment 1.631\n",
            "tick 75    kimg 300.0    time 6h 56m 37s   sec/tick 268.0   sec/kimg 67.00   maintenance 0.2    cpumem 5.38   gpumem 5.59   augment 1.654\n",
            "tick 76    kimg 304.0    time 7h 01m 06s   sec/tick 268.7   sec/kimg 67.19   maintenance 0.2    cpumem 5.37   gpumem 5.59   augment 1.677\n",
            "tick 77    kimg 308.0    time 7h 05m 35s   sec/tick 268.4   sec/kimg 67.09   maintenance 0.2    cpumem 5.37   gpumem 5.57   augment 1.696\n",
            "tick 78    kimg 312.0    time 7h 10m 03s   sec/tick 268.3   sec/kimg 67.08   maintenance 0.2    cpumem 5.37   gpumem 5.59   augment 1.716\n",
            "tick 79    kimg 316.0    time 7h 14m 32s   sec/tick 268.4   sec/kimg 67.09   maintenance 0.2    cpumem 5.37   gpumem 5.57   augment 1.736\n",
            "tick 80    kimg 320.0    time 7h 19m 01s   sec/tick 268.8   sec/kimg 67.20   maintenance 0.2    cpumem 5.36   gpumem 5.58   augment 1.757\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 63.80131190326486}, \"metric\": \"fid50k_full\", \"total_time\": 589.3649883270264, \"total_time_str\": \"9m 49s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000320.pkl\", \"timestamp\": 1643921474.5752938}\n",
            "tick 81    kimg 324.0    time 7h 33m 32s   sec/tick 268.0   sec/kimg 66.99   maintenance 603.5  cpumem 5.46   gpumem 5.63   augment 1.779\n",
            "tick 82    kimg 328.0    time 7h 38m 01s   sec/tick 268.8   sec/kimg 67.19   maintenance 0.2    cpumem 5.46   gpumem 5.57   augment 1.797\n",
            "tick 83    kimg 332.0    time 7h 42m 29s   sec/tick 268.0   sec/kimg 66.99   maintenance 0.2    cpumem 5.46   gpumem 5.57   augment 1.823\n",
            "tick 84    kimg 336.0    time 7h 46m 58s   sec/tick 268.8   sec/kimg 67.20   maintenance 0.2    cpumem 5.46   gpumem 5.59   augment 1.840\n",
            "tick 85    kimg 340.0    time 7h 51m 27s   sec/tick 268.4   sec/kimg 67.09   maintenance 0.2    cpumem 5.46   gpumem 5.57   augment 1.863\n",
            "tick 86    kimg 344.0    time 7h 55m 55s   sec/tick 268.4   sec/kimg 67.10   maintenance 0.2    cpumem 5.46   gpumem 5.60   augment 1.889\n",
            "tick 87    kimg 348.0    time 8h 00m 24s   sec/tick 268.4   sec/kimg 67.11   maintenance 0.2    cpumem 5.46   gpumem 5.56   augment 1.907\n",
            "tick 88    kimg 352.0    time 8h 04m 53s   sec/tick 268.8   sec/kimg 67.20   maintenance 0.2    cpumem 5.46   gpumem 5.59   augment 1.935\n",
            "tick 89    kimg 356.0    time 8h 09m 21s   sec/tick 268.0   sec/kimg 67.00   maintenance 0.2    cpumem 5.46   gpumem 5.58   augment 1.962\n",
            "tick 90    kimg 360.0    time 8h 13m 50s   sec/tick 268.7   sec/kimg 67.18   maintenance 0.2    cpumem 5.46   gpumem 5.59   augment 1.990\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 68.68291802687764}, \"metric\": \"fid50k_full\", \"total_time\": 586.0000977516174, \"total_time_str\": \"9m 46s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000360.pkl\", \"timestamp\": 1643924761.847087}\n",
            "tick 91    kimg 364.0    time 8h 28m 19s   sec/tick 268.0   sec/kimg 66.99   maintenance 601.4  cpumem 5.51   gpumem 5.59   augment 2.015\n",
            "tick 92    kimg 368.0    time 8h 32m 48s   sec/tick 268.6   sec/kimg 67.15   maintenance 0.2    cpumem 5.51   gpumem 5.57   augment 2.045\n",
            "tick 93    kimg 372.0    time 8h 37m 16s   sec/tick 268.2   sec/kimg 67.04   maintenance 0.2    cpumem 5.51   gpumem 5.62   augment 2.071\n",
            "tick 94    kimg 376.0    time 8h 41m 45s   sec/tick 268.1   sec/kimg 67.02   maintenance 0.2    cpumem 5.50   gpumem 5.60   augment 2.101\n",
            "tick 95    kimg 380.0    time 8h 46m 13s   sec/tick 268.4   sec/kimg 67.10   maintenance 0.2    cpumem 5.50   gpumem 5.57   augment 2.124\n",
            "tick 96    kimg 384.0    time 8h 50m 42s   sec/tick 268.7   sec/kimg 67.17   maintenance 0.2    cpumem 5.50   gpumem 5.59   augment 2.152\n",
            "tick 97    kimg 388.0    time 8h 55m 10s   sec/tick 267.9   sec/kimg 66.99   maintenance 0.2    cpumem 5.50   gpumem 5.61   augment 2.176\n",
            "tick 98    kimg 392.0    time 8h 59m 39s   sec/tick 268.7   sec/kimg 67.16   maintenance 0.2    cpumem 5.50   gpumem 5.58   augment 2.196\n",
            "tick 99    kimg 396.0    time 9h 04m 07s   sec/tick 267.8   sec/kimg 66.95   maintenance 0.2    cpumem 5.50   gpumem 5.57   augment 2.219\n",
            "tick 100   kimg 400.0    time 9h 08m 36s   sec/tick 268.7   sec/kimg 67.17   maintenance 0.2    cpumem 5.50   gpumem 5.61   augment 2.239\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 69.64381293174989}, \"metric\": \"fid50k_full\", \"total_time\": 583.9573512077332, \"total_time_str\": \"9m 44s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000400.pkl\", \"timestamp\": 1643928044.2764215}\n",
            "tick 101   kimg 404.0    time 9h 23m 02s   sec/tick 268.6   sec/kimg 67.14   maintenance 597.8  cpumem 5.50   gpumem 5.64   augment 2.260\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ],
      "source": [
        "!python train.py --outdir=outdir  --data=/content/stylegan2-ada-pytorch/data/pokemon256.zip \\\n",
        "    --gpus=1 --kimg=1000 --snap=10 \\\n",
        "    --resume=./outdir/checkpoints/latest.pth \\"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "stylegan2_ada_pokemon.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
